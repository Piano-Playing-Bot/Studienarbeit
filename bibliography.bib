
@online{muratoriImmediateModeGraphicalUser,
	title = {Immediate-Mode Graphical User Interfaces (2005)},
	url = {https://caseymuratori.com/blog_0001},
	abstract = {An old makeshift tech video I recorded introducing the concept of “{IMGUI}”  —  the Immediate-Mode Graphical User Interface.},
	titleaddon = {Immediate-Mode Graphical User Interfaces (2005)},
	author = {Muratori, Casey},
	urldate = {2023-10-12},
	langid = {english},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\R5BJRIEB\\blog_0001.html:text/html},
}

@article{brendelExploringImmediateMode2022,
	title = {Exploring the Immediate Mode {GUI} Concept for Graphical User Interfaces in Mixed Reality Applications},
	url = {https://dl.gi.de/handle/20.500.12116/40168},
	doi = {10.18420/vrar2022_1678},
	abstract = {The state of the art {GUI} is based on widget lifetimes that are bound to objects or handles. This common approach which is called retained mode {GUI} has a few drawbacks. The application data has to be kept in sync with the {UI} manually. An alternative approach is the immediate mode {GUI} which differs from retained mode in that no {UI} widget has a lifetime and does not require updates. In every frame, the application instructs the immediate mode system what to display on the screen. Immediate mode {GUI} systems are already widely used in games and game tooling. In this work, the possibilities of an immediate mode system in the context of mixed reality are explored.},
	pages = {12},
	journaltitle = {Gesellschaft für Informatik e.V.},
	author = {Brendel, Felix},
	urldate = {2024-01-11},
	date = {2022},
	langid = {english},
	file = {Brendel - Exploring the Immediate Mode GUI Concept for Graph.pdf:C\:\\Users\\OS\\Zotero\\storage\\XHX7LGQZ\\Brendel - Exploring the Immediate Mode GUI Concept for Graph.pdf:application/pdf},
}

@misc{midiassociationMIDICapabilityInquiry2020,
	title = {{MIDI} Capability Inquiry ({MIDI}-{CI})},
	shorttitle = {M2-101-{UM}},
	version = {1.0},
	pagetotal = {54},
	publisher = {Association of Musical Electronics Industry {AMEI}, {MIDI} Manufacturers Association {MMA}},
	author = {{MIDI} Association},
	date = {2020-02-20},
	langid = {english},
	file = {2020 - MIDI Capability Inquiry (MIDI-CI).pdf:C\:\\Users\\OS\\Zotero\\storage\\4NPUC2VT\\2020 - MIDI Capability Inquiry (MIDI-CI).pdf:application/pdf},
}

@misc{midiassociationUniversalMIDIPacket2020,
	title = {Universal {MIDI} Packet ({UMP}) Format and {MIDI} 2.0 Protocol},
	shorttitle = {M2-103-{UM}},
	version = {1.0},
	pagetotal = {80},
	publisher = {Association of Musical Electronics Industry {AMEI}, {MIDI} Manufacturers Association {MMA}},
	author = {{MIDI} Association},
	date = {2020-02-20},
	langid = {english},
	file = {2020 - Universal MIDI Packet (UMP) Format and MIDI 2.0 Pr.pdf:C\:\\Users\\OS\\Zotero\\storage\\LTPHJU9H\\2020 - Universal MIDI Packet (UMP) Format and MIDI 2.0 Pr.pdf:application/pdf},
}

@misc{midiassociationCommonRulesMIDICI2020,
	title = {Common Rules for {MIDI}-{CI} Profiles},
	shorttitle = {M2-100-U},
	version = {1.0},
	pagetotal = {17},
	publisher = {Association of Musical Electronics Industry {AMEI}, {MIDI} Manufacturers Association {MMA}},
	author = {{MIDI} Association},
	date = {2020-02-20},
	langid = {english},
	file = {2020 - Common Rules for MIDI-CI Profiles.pdf:C\:\\Users\\OS\\Zotero\\storage\\6VAREZTK\\2020 - Common Rules for MIDI-CI Profiles.pdf:application/pdf},
}

@misc{midiassociationMIDISpecificationOverview2020,
	title = {{MIDI} 2.0 Specification Overview},
	shorttitle = {M2-100-U},
	version = {1.0},
	pagetotal = {5},
	publisher = {Association of Musical Electronics Industry {AMEI}, {MIDI} Manufacturers Association {MMA}},
	author = {{MIDI} Association},
	date = {2020-02-20},
	langid = {english},
	file = {2020 - MIDI 2.0 Specification Overview.pdf:C\:\\Users\\OS\\Zotero\\storage\\9JKP29KW\\2020 - MIDI 2.0 Specification Overview.pdf:application/pdf},
}

@book{midiassociationCompleteMIDIDetailed1996,
	edition = {3rd},
	title = {The Complete {MIDI} 1.0 Detailed Specification},
	shorttitle = {{MIDI} version 96.1},
	pagetotal = {334},
	publisher = {Association of Musical Electronics Industry {AMEI}, {MIDI} Manufacturers Association {MMA}},
	author = {{MIDI} Association},
	date = {1996},
	langid = {english},
	file = {1996 - The Complete MIDI 1.0 Detailed Specification.pdf:C\:\\Users\\OS\\Zotero\\storage\\VT9J5VWU\\1996 - The Complete MIDI 1.0 Detailed Specification.pdf:application/pdf},
}

@online{midiassociationControlChangeMessages,
	title = {Control Change Messages (Data Bytes)},
	url = {https://docs.google.com/viewer?url=https://midi.org/component/edocman/midi-1-0-control-change-messages-data-bytes-2/fdocument?Itemid=9999},
	author = {{MIDI} Association},
	urldate = {2023-10-10},
	file = {Control Change Messages (Data Bytes).pdf:C\:\\Users\\OS\\Zotero\\storage\\Y8K2RSTM\\Control Change Messages (Data Bytes).pdf:application/pdf},
}

@online{midiassociationSummaryMIDIMessages,
	title = {Summary of {MIDI} 1.0 Messages},
	url = {https://midi.org/specifications-old/item/table-1-summary-of-midi-message},
	author = {{MIDI} Association},
	urldate = {2023-10-10},
	file = {Summary of MIDI 1.0 Messages:C\:\\Users\\OS\\Zotero\\storage\\MGV7Q258\\table-1-summary-of-midi-message.html:text/html},
}

@incollection{lehrmanWhatMIDI2017,
	title = {What is {MIDI}},
	pages = {21},
	booktitle = {{MIDI} For The Professional},
	author = {Lehrman, Paul D and Tully, Tim},
	date = {2017},
	langid = {english},
	file = {Lehrman and Tully - 2017 - What is MIDI.pdf:C\:\\Users\\OS\\Zotero\\storage\\ZDCER2SN\\Lehrman and Tully - 2017 - What is MIDI.pdf:application/pdf},
}

@book{warrenArduinoRobotics2011,
	location = {Berkeley, {CA}},
	title = {Arduino Robotics},
	isbn = {978-1-4302-3183-7 978-1-4302-3184-4},
	url = {http://link.springer.com/10.1007/978-1-4302-3184-4},
	publisher = {Apress},
	author = {Warren, John-David and Adams, Josh and Molle, Harald},
	urldate = {2023-10-09},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-1-4302-3184-4},
	file = {Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\2QN7IFC5\\Warren et al. - 2011 - Arduino Robotics.pdf:application/pdf},
}

@online{arduinoArduinoLibrariesReference,
	title = {Arduino Libraries Reference},
	url = {https://www.arduino.cc/reference/en/libraries/},
	author = {Arduino},
	urldate = {2023-10-09},
	file = {Libraries - Arduino Reference:C\:\\Users\\OS\\Zotero\\storage\\BDE4ULEP\\libraries.html:text/html},
}

@online{arduinoArduinoLanguageReference,
	title = {Arduino Language Reference},
	url = {https://www.arduino.cc/reference/en/},
	author = {Arduino},
	urldate = {2023-10-09},
	file = {Arduino Reference - Arduino Reference:C\:\\Users\\OS\\Zotero\\storage\\XF2XMQ94\\en.html:text/html},
}

@inproceedings{badamasiWorkingPrincipleArduino2014,
	title = {The working principle of an Arduino},
	url = {https://ieeexplore.ieee.org/abstract/document/6997578?casa_token=5FGGwxoDCbAAAAAA%3A2Kt35-pw_cq4RCF75T0h43ZihPZ5vtPwKCtEBx5h9f7IZQGhBw6AmoHxd3P0TD6kypA3a5RZ7JFA},
	doi = {10.1109/ICECCO.2014.6997578},
	abstract = {In this paper, we analyze the working principle of an arduino. These days many people try to use the arduino because it makes things easier due to the simplified version of C++ and the already made Arduino microcontroller(atmega328 microcontroller [1]) that you can programme, erase and reprogramme at any given time. In this paper we will discuss the hardware components used in the arduino board, the software used to programme it (Arduino board) with the guide on how to write and construct your own projects, and a couple of examples of an arduino project, This will give you the overall view of an arduino uno, that after reading this paper you will get the basic concept and use of an arduino uno.},
	eventtitle = {2014 11th International Conference on Electronics, Computer and Computation ({ICECCO})},
	pages = {1--4},
	booktitle = {2014 11th International Conference on Electronics, Computer and Computation ({ICECCO})},
	author = {Badamasi, Yusuf Abdullahi},
	urldate = {2023-10-09},
	date = {2014-09},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\OS\\Zotero\\storage\\KJ5QQMSE\\6997578.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\2XYQJIMC\\Badamasi - 2014 - The working principle of an Arduino.pdf:application/pdf},
}

@article{malheiroAutomaticMusicalInstrument,
	title = {Automatic Musical Instrument and Note Recognition},
	abstract = {We propose a sound recognizer that uses a reduced feature set to identify musical instruments from single notes in sound recordings as well as the note that was played. The recognizer learns a set of spectral features from the data using non-negative matrix factorization.},
	author = {Malheiro, Frederico and Cavaco, Soﬁa},
	langid = {english},
	file = {Malheiro and Cavaco - Automatic Musical Instrument and Note Recognition.pdf:C\:\\Users\\OS\\Zotero\\storage\\LW7L6REP\\Malheiro and Cavaco - Automatic Musical Instrument and Note Recognition.pdf:application/pdf},
}

@article{kuhnRealTimePitchRecognition1990,
	title = {A Real-Time Pitch Recognition Algorithm for Music Applications},
	volume = {14},
	issn = {01489267, 15315169},
	url = {http://www.jstor.org/stable/3679960},
	doi = {10.2307/3679960},
	pages = {60--71},
	number = {3},
	journaltitle = {Computer Music Journal},
	author = {Kuhn, William B.},
	urldate = {2023-10-09},
	date = {1990},
	note = {Publisher: The {MIT} Press},
	file = {Kuhn - 1990 - A Real-Time Pitch Recognition Algorithm for Music .pdf:C\:\\Users\\OS\\Zotero\\storage\\SQ6ZGGQU\\Kuhn - 1990 - A Real-Time Pitch Recognition Algorithm for Music .pdf:application/pdf},
}

@article{siegerAudioCodingRepresentation1998,
	title = {Audio Coding for Representation in {MIDI} via Pitch Detection Using Harmonic Dictionaries},
	volume = {20},
	issn = {0922-5773},
	url = {https://doi.org/10.1023/A:1008074130468},
	doi = {10.1023/A:1008074130468},
	abstract = {The search for a flexible and concise alternate representation for digital musical sound leads to the proposal for the use of the {MIDI} (Musical Instrument Digital Interface) protocol. The problem becomes one of automating the conversion process from sound to {MIDI}. This requires processing musical sound and extracting the information necessary to represent the sound as {MIDI} data. We have conducted studies which have led to algorithms for segmentation of the sound and pitch detection of the individual notes. We describe a novel method for pitch detection using subset selection with dictionaries containing harmonic spectra from samples of musical sounds. Examples demonstrating applicability to monophonic sounds as well as signals with multiple sound sources are given, including detection of objects in a complex background scene.},
	pages = {45--59},
	number = {1},
	journaltitle = {Journal of {VLSI} signal processing systems for signal, image and video technology},
	shortjournal = {The Journal of {VLSI} Signal Processing-Systems for Signal, Image, and Video Technology},
	author = {Sieger, Nicholas J. and Tewfik, Ahmed H.},
	urldate = {2023-10-09},
	date = {1998-10-01},
	langid = {english},
	keywords = {Audio Code, Frequency Track, Harmonic Spectrum, Musical Sound, Subset Selection},
	file = {Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\U4U5LHTN\\Sieger and Tewfik - 1998 - Audio Coding for Representation in MIDI via Pitch .pdf:application/pdf},
}

@inproceedings{guerrero-turrubiatesPitchEstimationMusical2014,
	title = {Pitch estimation for musical note recognition using Artificial Neural Networks},
	url = {https://ieeexplore.ieee.org/document/6808567},
	doi = {10.1109/CONIELECOMP.2014.6808567},
	abstract = {Pitch estimation has increased its importance due to the wide variety of applications in different fields, e.g. speech and voice recognition, music transcription, to name a few. Musical signals may contain noise and distortion, therefore pitch detection results can be erroneous. In this paper, a musical note recognition system based on harmonic modification and Artificial Neural Network ({ANN}) is proposed. At first, downsampling is applied to convert the signal from 44,100 Hz sampling rate to 2,100 Hz. Fast Fourier Transform ({FFT}) is used to obtain the signal spectrum; Harmonic Product Spectrum ({HPS}) algorithm is implemented to enhance the fundamental frequency amplitude. Then a dimensionality reduction method based on variances, is used to extract relevant information from the input signal. In the present work, audio signals were taken from a proprietary database that was constructed using an electric guitar as audio source. The classification is performed by a feed-forward neural network or Multi-Layer Perceptron ({MLP}). Experimental results present accurate classification with few processing of the input signal. Besides the proposed approach presents enough robustness to classify musical notes coming from different musical instruments.},
	eventtitle = {2014 International Conference on Electronics, Communications and Computers ({CONIELECOMP})},
	pages = {53--58},
	booktitle = {2014 International Conference on Electronics, Communications and Computers ({CONIELECOMP})},
	author = {Guerrero-Turrubiates, Jose de Jesus and Gonzalez-Reyna, Sheila Esmeralda and Ledesma-Orozco, Sergio Eduardo and Avina-Cervantes, Juan Gabriel},
	urldate = {2023-10-09},
	date = {2014-02},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\OS\\Zotero\\storage\\XJXPLBP8\\6808567.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\URX2TQFH\\Guerrero-Turrubiates et al. - 2014 - Pitch estimation for musical note recognition usin.pdf:application/pdf},
}

@inproceedings{guerrero-turrubiatesPitchEstimationMusical2014a,
	title = {Pitch estimation for musical note recognition using Artificial Neural Networks},
	url = {https://ieeexplore.ieee.org/abstract/document/6808567?casa_token=RjffFklm15UAAAAA%3A132QZxiw77tfT5m8aOonYObRwptiChUK1LRcgGoz0A5XTG840g_JhqgkDqR0UgaUEaE0FXJC0MP9},
	doi = {10.1109/CONIELECOMP.2014.6808567},
	abstract = {Pitch estimation has increased its importance due to the wide variety of applications in different fields, e.g. speech and voice recognition, music transcription, to name a few. Musical signals may contain noise and distortion, therefore pitch detection results can be erroneous. In this paper, a musical note recognition system based on harmonic modification and Artificial Neural Network ({ANN}) is proposed. At first, downsampling is applied to convert the signal from 44,100 Hz sampling rate to 2,100 Hz. Fast Fourier Transform ({FFT}) is used to obtain the signal spectrum; Harmonic Product Spectrum ({HPS}) algorithm is implemented to enhance the fundamental frequency amplitude. Then a dimensionality reduction method based on variances, is used to extract relevant information from the input signal. In the present work, audio signals were taken from a proprietary database that was constructed using an electric guitar as audio source. The classification is performed by a feed-forward neural network or Multi-Layer Perceptron ({MLP}). Experimental results present accurate classification with few processing of the input signal. Besides the proposed approach presents enough robustness to classify musical notes coming from different musical instruments.},
	eventtitle = {2014 International Conference on Electronics, Communications and Computers ({CONIELECOMP})},
	pages = {53--58},
	booktitle = {2014 International Conference on Electronics, Communications and Computers ({CONIELECOMP})},
	author = {Guerrero-Turrubiates, Jose de Jesus and Gonzalez-Reyna, Sheila Esmeralda and Ledesma-Orozco, Sergio Eduardo and Avina-Cervantes, Juan Gabriel},
	urldate = {2023-10-09},
	date = {2014-02},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\OS\\Zotero\\storage\\RZPCF5Z3\\6808567.html:text/html},
}

@inproceedings{liuRobustMethodMusical2015,
	title = {A Robust Method for Musical Note Recognition},
	url = {https://ieeexplore.ieee.org/abstract/document/7450422/references#references},
	doi = {10.1109/CADGRAPHICS.2015.34},
	abstract = {Musical note recognition plays a fundamental role in the process of the optical music recognition system. In this paper, we propose a robust method for recognizing notes. The method includes three parts: (1) the description of relationships between primitives by introducing the concept of interaction field, (2) the definition of six hierarchical structure features for analyzing notes structures, (3) the workflow of primitive assembly under the guidance of giving priority to key structure features. To evaluate the performance of our method, we present experimental results on real-life scores and comparisons with two commercial products. Experiment show that our method lead to quite good results, especially for complicated scores.},
	eventtitle = {2015 14th International Conference on Computer-Aided Design and Computer Graphics ({CAD}/Graphics)},
	pages = {212--213},
	booktitle = {2015 14th International Conference on Computer-Aided Design and Computer Graphics ({CAD}/Graphics)},
	author = {Liu, Xiaoxiang and Zhou, Mi and Xu, Peng},
	urldate = {2023-10-09},
	date = {2015-08},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\OS\\Zotero\\storage\\9CJ8YX9Z\\references.html:text/html},
}

@article{rossantRobustAdaptiveOMR2007,
	title = {Robust and adaptive {OMR} system including Fuzzy modeling, fusion of musical rules, and possible error detection},
	volume = {2007},
	issn = {1110-8657},
	url = {https://dl.acm.org/doi/10.1155/2007/81541},
	doi = {10.1155/2007/81541},
	abstract = {This paper describes a system for optical music recognition ({OMR}) in case of monophonic typeset scores. After clarifying the difficulties specific to this domain, we propose appropriate solutions at both image analysis level and high-level interpretation. Thus, a recognition and segmentation method is designed, that allows dealing with common printing defects and numerous symbol interconnections. Then, musical rules are modeled and integrated, in order to make a consistent decision. This high-level interpretation step relies on the fuzzy sets and possibility framework, since it allows dealing with symbol variability, flexibility, and imprecision of music rules, and merging all these heterogeneous pieces of information. Other innovative features are the indication of potential errors and the possibility of applying learning procedures, in order to gain in robustness. Experiments conducted on a large data base show that the proposed method constitutes an interesting contribution to {OMR}.},
	pages = {160},
	number = {1},
	journaltitle = {{EURASIP} Journal on Advances in Signal Processing},
	shortjournal = {{EURASIP} J. Adv. Signal Process},
	author = {Rossant, Florence and Bloch, Isabelle},
	urldate = {2023-10-09},
	date = {2007-01-01},
	file = {Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\L88UB7Q8\\Rossant and Bloch - 2007 - Robust and adaptive OMR system including Fuzzy mod.pdf:application/pdf},
}

@book{georgeVisualPerceptionMusic2004,
	title = {Visual Perception of Music Notation: On-Line and Off-Line Recognition},
	isbn = {1-59140-298-0},
	abstract = {In this text for undergraduate and graduate students in technology-related music programs, George (U. of South Australia) and contributors describe computer recognition of music notation, including off-line music processing, handwritten music recognition, and lyric recognition. Chapter topics include staff detection and removal, a method of off-line optical music sheet recognition, using wavelets to deal with superimposed objects, pen-based input for online hand-written notation, lyric recognition and Christian music, and multilingual lyric modeling and management. In a section covering music description and its applications, contributors examine constructing emotional landscapes with music and modeling music notations in the Internet multimedia age. The final chapter describes evaluation in the visual perception of music},
	pagetotal = {357},
	publisher = {{IRM} Press, Idea Group Inc.},
	author = {George, Susan Ella},
	date = {2004},
	langid = {english},
}

@article{younisNewParallelBat2021,
	title = {A new parallel bat algorithm for musical note recognition},
	volume = {11},
	issn = {2722-2578, 2088-8708},
	url = {http://ijece.iaescore.com/index.php/IJECE/article/view/21964},
	doi = {10.11591/ijece.v11i1.pp558-566},
	abstract = {Music is a universal language that does not require an interpreter, where feelings and sensitivities are united, regardless of the different peoples and languages, The proposed system consists of two main stages: the process of extracting important properties using the linear discrimination analysis ({LDA}) This step is carried out after the initial treatment process using various procedures to remove musical lines, The second stage describes the recognition process using the bat algorithm, which is one of the metaheuristic algorithms after modifying the bat algorithm to obtain better discriminating results. The proposed system was supported by parallel implementation using the (developed bat algorithm {DBA}), which increased the speed of implementation significantly. The method was applied to 1250 different images of musical notes. The proposed system was implemented using {MATLAB} R2016a, Work was done on a Windows10 Processor {OS} (Intel ® Core {TM} i5-7200U {CPU} @ 2.50GHZ 2.70GHZ) computer.},
	pages = {558},
	number = {1},
	journaltitle = {International Journal of Electrical and Computer Engineering ({IJECE})},
	shortjournal = {{IJECE}},
	author = {Younis, Ansam Nazar and Ramo, Fawzia Mahmood},
	urldate = {2023-10-09},
	date = {2021-02-01},
	langid = {english},
	file = {Younis and Ramo - 2021 - A new parallel bat algorithm for musical note reco.pdf:C\:\\Users\\OS\\Zotero\\storage\\PUBRZKLR\\Younis and Ramo - 2021 - A new parallel bat algorithm for musical note reco.pdf:application/pdf},
}

@inproceedings{yooMaskMatchingLow2008,
	title = {Mask Matching for Low Resolution Musical Note Recognition},
	url = {https://ieeexplore.ieee.org/abstract/document/4775718?casa_token=-98YXKClqN8AAAAA%3AiXS8uiwbRywp0_0Z6A3sPyDMDUuduV0V5CFMsAGzz9aaFz29pwVbto9iag6eCWagbClsV45Pb1xq},
	doi = {10.1109/ISSPIT.2008.4775718},
	abstract = {In this paper, we deal with the recognition of musical scores in a low resolution image captured by the digital camera of a mobile phone. Compared to clean, scanned images, low resolution images contain music scores with severe distortions or irrecoverable discontinuities. Most of existing approaches for scanned music scores cannot be applied to the scores with such damages. In this paper, we present mask based approach to cope with incomplete information in the low resolution image. We mainly focus on musical notes in this paper. After the separation of objects in the score into symbols and musical notes, musical notes are identified by mask matching. For the head of a musical note, a 2D head mask is employed while 1D mask is used to extract features for tails. Experimental results show the effectiveness of our approach with the recognition rate of close to 100\% in sample images.},
	eventtitle = {2008 {IEEE} International Symposium on Signal Processing and Information Technology},
	pages = {223--226},
	booktitle = {2008 {IEEE} International Symposium on Signal Processing and Information Technology},
	author = {Yoo, {JaeMyeong} and Kim, {GiHong} and Lee, {GueeSang}},
	urldate = {2023-10-09},
	date = {2008-12},
	note = {{ISSN}: 2162-7843},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\OS\\Zotero\\storage\\HY6Y4L3J\\4775718.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\MZEH8R3Q\\Yoo et al. - 2008 - Mask Matching for Low Resolution Musical Note Reco.pdf:application/pdf},
}

@online{shatriOpticalMusicRecognition2020,
	title = {Optical Music Recognition: State of the Art and Major Challenges},
	url = {https://arxiv.org/abs/2006.07885v2},
	shorttitle = {Optical Music Recognition},
	abstract = {Optical Music Recognition ({OMR}) is concerned with transcribing sheet music into a machine-readable format. The transcribed copy should allow musicians to compose, play and edit music by taking a picture of a music sheet. Complete transcription of sheet music would also enable more efficient archival. {OMR} facilitates examining sheet music statistically or searching for patterns of notations, thus helping use cases in digital musicology too. Recently, there has been a shift in {OMR} from using conventional computer vision techniques towards a deep learning approach. In this paper, we review relevant works in {OMR}, including fundamental methods and significant outcomes, and highlight different stages of the {OMR} pipeline. These stages often lack standard input and output representation and standardised evaluation. Therefore, comparing different approaches and evaluating the impact of different processing methods can become rather complex. This paper provides recommendations for future work, addressing some of the highlighted issues and represents a position in furthering this important field of research.},
	titleaddon = {{arXiv}.org},
	author = {Shatri, Elona and Fazekas, György},
	urldate = {2023-10-09},
	date = {2020-06-14},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\2WATQUUN\\Shatri and Fazekas - 2020 - Optical Music Recognition State of the Art and Ma.pdf:application/pdf},
}

@article{tamboliEffectiveOptimizationBasedNeural2019,
	title = {An Effective Optimization-Based Neural Network for Musical Note Recognition},
	volume = {28},
	rights = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	issn = {2191-026X},
	url = {https://www.degruyter.com/document/doi/10.1515/jisys-2017-0038/html},
	doi = {10.1515/jisys-2017-0038},
	abstract = {Musical pitch estimation is used to recognize the musical note pitch or the fundamental frequency ( F 0 ) of an audio signal, which can be applied to a preprocessing part of many applications, such as sound separation and musical note transcription. In this work, a method for musical note recognition based on the classification framework has been designed using an optimization-based neural network ({OBNN}). A broad range of survey and research was reviewed, and all revealed the methods to recognize the musical notes. An {OBNN} is used here in recognizing musical notes. Similarly, we can progress the effectiveness of musical note recognition using different methodologies. In this document, the most modern investigations related to musical note recognition are effectively analyzed and put in a nutshell to effectively furnish the traits and classifications.},
	pages = {173--183},
	number = {1},
	journaltitle = {Journal of Intelligent Systems},
	author = {Tamboli, Allabakash Isak and Kokate, Rajendra D.},
	urldate = {2023-10-09},
	date = {2019-01-01},
	langid = {english},
	note = {Publisher: De Gruyter},
	keywords = {Audio signal, musical notes, neural network, optimization},
	file = {Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\G2DDBDXH\\Tamboli and Kokate - 2019 - An Effective Optimization-Based Neural Network for.pdf:application/pdf},
}

@inproceedings{baroRecognitionCompoundMusic2016,
	title = {Towards the Recognition of Compound Music Notes in Handwritten Music Scores},
	url = {https://ieeexplore.ieee.org/abstract/document/7814108?casa_token=0t5S-NtZEYMAAAAA%3AU0G8OisDLl5-tXydyOuRUkvBlj5nMVAAiYbb7NdswRVt0vn-soeUjTX2aHFTQSWzhLo-PO7DHCOR},
	doi = {10.1109/ICFHR.2016.0092},
	abstract = {The recognition of handwritten music scores still remains an open problem. The existing approaches can only deal with very simple handwritten scores mainly because of the variability in the handwriting style and the variability in the composition of groups of music notes (i.e. compound music notes). In this work we focus on this second problem and propose a method based on perceptual grouping for the recognition of compound music notes. Our method has been tested using several handwritten music scores of the {CVC}-{MUSCIMA} database and compared with a commercial Optical Music Recognition ({OMR}) software. Given that our method is learning-free, the obtained results are promising.},
	eventtitle = {2016 15th International Conference on Frontiers in Handwriting Recognition ({ICFHR})},
	pages = {465--470},
	booktitle = {2016 15th International Conference on Frontiers in Handwriting Recognition ({ICFHR})},
	author = {Baró, Arnau and Riba, Pau and Fornés, Alicia},
	urldate = {2023-10-09},
	date = {2016-10},
	note = {{ISSN}: 2167-6445},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\UJAC9WB3\\Baró et al. - 2016 - Towards the Recognition of Compound Music Notes in.pdf:application/pdf},
}

@article{calvo-zaragozaUnderstandingOpticalMusic2020,
	title = {Understanding Optical Music Recognition},
	volume = {53},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3397499},
	doi = {10.1145/3397499},
	abstract = {For over 50 years, researchers have been trying to teach computers to read music notation, referred to as Optical Music Recognition ({OMR}). However, this field is still difficult to access for new researchers, especially those without a significant musical background: Few introductory materials are available, and, furthermore, the field has struggled with defining itself and building a shared terminology. In this work, we address these shortcomings by (1) providing a robust definition of {OMR} and its relationship to related fields, (2) analyzing how {OMR} inverts the music encoding process to recover the musical notation and the musical semantics from documents, and (3) proposing a taxonomy of {OMR}, with most notably a novel taxonomy of applications. Additionally, we discuss how deep learning affects modern {OMR} research, as opposed to the traditional pipeline. Based on this work, the reader should be able to attain a basic understanding of {OMR}: its objectives, its inherent structure, its relationship to other fields, the state of the art, and the research opportunities it affords.},
	pages = {77:1--77:35},
	number = {4},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Calvo-Zaragoza, Jorge and Jr., Jan Hajič and Pacha, Alexander},
	urldate = {2023-10-09},
	date = {2020-07-22},
	keywords = {music notation, music scores, Optical music recognition},
	file = {Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\I4BYU4K6\\Calvo-Zaragoza et al. - 2020 - Understanding Optical Music Recognition.pdf:application/pdf},
}

@article{baroOpticalMusicRecognition2019,
	title = {From Optical Music Recognition to Handwritten Music Recognition: A baseline},
	volume = {123},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865518303386},
	doi = {10.1016/j.patrec.2019.02.029},
	shorttitle = {From Optical Music Recognition to Handwritten Music Recognition},
	abstract = {Optical Music Recognition ({OMR}) is the branch of document image analysis that aims to convert images of musical scores into a computer-readable format. Despite decades of research, the recognition of handwritten music scores, concretely the Western notation, is still an open problem, and the few existing works only focus on a specific stage of {OMR}. In this work, we propose a full Handwritten Music Recognition ({HMR}) system based on Convolutional Recurrent Neural Networks, data augmentation and transfer learning, that can serve as a baseline for the research community.},
	pages = {1--8},
	journaltitle = {Pattern Recognition Letters},
	shortjournal = {Pattern Recognition Letters},
	author = {Baró, Arnau and Riba, Pau and Calvo-Zaragoza, Jorge and Fornés, Alicia},
	urldate = {2023-10-09},
	date = {2019-05-15},
	keywords = {Optical music recognition, Deep neural networks, Document image analysis and recognition, Handwritten music recognition, {LSTM}},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\UFQ9V2QR\\Baró et al. - 2019 - From Optical Music Recognition to Handwritten Musi.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\OS\\Zotero\\storage\\M9WMJKJ6\\S0167865518303386.html:text/html},
}

@inreference{wikipediaMikrocontroller2023,
	title = {Mikrocontroller},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://de.wikipedia.org/w/index.php?title=Mikrocontroller&oldid=237392385},
	abstract = {Als Mikrocontroller (auch µController, µC, {MCU} oder Einchipmikrorechner) werden Halbleiterchips bezeichnet, die einen Prozessor und zugleich auch Peripheriefunktionen enthalten. In vielen Fällen befindet sich auch der Arbeits- und Programmspeicher teilweise oder komplett auf demselben Chip. Ein Mikrocontroller ist ein Ein-Chip-Computersystem. Für manche Mikrocontroller wird auch der Begriff System-on-a-Chip ({SoC}) verwendet.
Auf modernen Mikrocontrollern finden sich häufig auch komplexe Peripheriefunktionen wie z. B. {CAN}- (Controller Area Network), {LIN}- (Local Interconnect Network), {USB}- (Universal Serial Bus), I²C- (Inter-Integrated Circuit), {SPI}- (Serial Peripheral Interface), serielle oder Ethernet-Schnittstellen, {PDM}-Ausgänge, {LCD}-Controller und -Treiber sowie Analog-Digital-Umsetzer. Einige Mikrocontroller verfügen auch über programmierbare digitale und/oder analoge bzw. hybride Funktionsblöcke.},
	booktitle = {Wikipedia},
	author = {Wikipedia},
	urldate = {2023-10-27},
	date = {2023-09-16},
	langid = {german},
	note = {Page Version {ID}: 237392385},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\SYZB5DXH\\Mikrocontroller.html:text/html},
}

@online{vandenneuckerMIDITutorialProgrammers,
	title = {{MIDI} tutorial for programmers},
	url = {http://www.music-software-development.com/midi-tutorial.html},
	abstract = {This {MIDI} tutorial will help programmers understand the {MIDI} language},
	author = {Vandenneucker, Dominique},
	urldate = {2023-11-02},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\EEI2AN7D\\MIDI tutorial for programmers.html:text/html},
}

@online{midiassociationExpandedMIDIMessages,
	title = {Expanded {MIDI} 1.0 Messages List (Status Bytes)},
	url = {https://midi.org/specifications-old/item/table-2-expanded-messages-list-status-bytes},
	author = {{MIDI} Association},
	urldate = {2023-10-10},
}

@online{arduinoGettingStartedArduino,
	title = {Getting Started with Arduino {\textbar} Arduino Documentation},
	url = {https://docs.arduino.cc/learn/starting-guide/getting-started-arduino},
	abstract = {An introduction to hardware, software tools, and the Arduino {API}.},
	author = {Arduino},
	urldate = {2024-01-01},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\7Y24QCHY\\getting-started-arduino.html:text/html},
}

@online{YamahaU1Enspire,
	title = {Yamaha U1 Enspire {ST} - Disklavier Enspire Silent - in weiß - Musikinstrumente und Musikzubehör},
	url = {https://www.pianelli.de/yamaha-u1-enst-disklavier-enspire-silent-in-weiss.html},
	urldate = {2024-03-11},
	file = {Yamaha U1 Enspire ST - Disklavier Enspire Silent - in weiß - Musikinstrumente und Musikzubehör:C\:\\Users\\OS\\Zotero\\storage\\9P93MHDW\\yamaha-u1-enst-disklavier-enspire-silent-in-weiss.html:text/html},
}

@article{mylopoulosIIIStructuredAnalysis2004,
	title = {{III}. Structured Analysis and Design Technique ({SADT})},
	author = {Mylopoulos, John},
	date = {2004},
	langid = {english},
	file = {Mylopoulos - III. Structured Analysis and Design Technique (SAD.pdf:C\:\\Users\\OS\\Zotero\\storage\\P6ZDDUS8\\Mylopoulos - III. Structured Analysis and Design Technique (SAD.pdf:application/pdf},
}

@misc{MP3,
	title = {{ISO}/{IEC} 11172-3:1993},
	url = {https://www.iso.org/standard/22412.html},
	shorttitle = {{ISO}/{IEC} 11172-3},
	abstract = {Information technology — Coding of moving pictures and associated audio for digital storage media at up to about 1,5 Mbit/s — Part 3: Audio},
	pagetotal = {150},
	publisher = {{ISO}},
	urldate = {2024-03-02},
	date = {1993-08},
	langid = {english},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\MKLSR4ZF\\22412.html:text/html},
}

@online{ZimmermannKlavier1000x667Jpg1000,
	title = {Zimmermann-Klavier-1000x667.jpg (1000×667)},
	url = {https://klaviergeschaeft-berlin.de/wp-content/uploads/2018/03/Zimmermann-Klavier-1000x667.jpg},
	urldate = {2024-02-28},
	file = {Zimmermann-Klavier-1000x667.jpg (1000×667):C\:\\Users\\OS\\Zotero\\storage\\4XKLUCQ3\\Zimmermann-Klavier-1000x667.html:text/html},
}

@online{ZimmermannKlavier1000x667Jpg1000a,
	title = {Zimmermann-Klavier-1000x667.jpg (1000×667)},
	url = {https://klaviergeschaeft-berlin.de/wp-content/uploads/2018/03/Zimmermann-Klavier-1000x667.jpg},
	urldate = {2024-02-28},
	file = {Zimmermann-Klavier-1000x667.jpg (1000×667):C\:\\Users\\OS\\Zotero\\storage\\T3HAHD3E\\Zimmermann-Klavier-1000x667.html:text/html},
}

@online{fleuryEasiestWayHandle2023,
	title = {The Easiest Way To Handle Errors Is To Not Have Them},
	url = {https://www.rfleury.com/p/the-easiest-way-to-handle-errors},
	abstract = {The "why" and "how" of computing. Click to read Hidden Grove, by Ryan Fleury, a Substack publication with thousands of subscribers.},
	author = {Fleury, Ryan},
	urldate = {2024-02-22},
	date = {2023-12-29},
	langid = {english},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\AP4FPBHN\\the-easiest-way-to-handle-errors.html:text/html},
}

@online{muratoriDesigningEvaluatingReusable2014,
	title = {Designing and Evaluating Reusable Components (2004)},
	url = {https://caseymuratori.com/blog_0024},
	abstract = {An in-depth look at the five core principles of {API} design.},
	titleaddon = {Designing and Evaluating Reusable Components (2004)},
	author = {Muratori, Casey},
	urldate = {2024-02-22},
	date = {2014-07-30},
	langid = {english},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\RT9YJIJR\\blog_0024.html:text/html},
}

@online{muratoriSemanticCompression2014,
	title = {Semantic Compression},
	url = {https://caseymuratori.com/blog_0015},
	abstract = {An introduction to the idea that code should be approached with a mindset towards compressing it semantically, rather than orienting it around objects.},
	titleaddon = {Semantic Compression},
	author = {Muratori, Casey},
	urldate = {2024-02-22},
	date = {2014-05-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\QQLPSQ5Y\\blog_0015.html:text/html},
}

@book{fabianDataOrientedDesign2018,
	title = {Data-Oriented Design},
	url = {https://www.dataorienteddesign.com/dodbook/node2.html},
	abstract = {The projects tackled by the software development industry have grown in scale and complexity. Costs are increasing along with the number of developers. Power bills for distributed projects have reached the point where optimisations pay literal dividends. Over the last 10 years, a software development movement has gained traction, a movement founded in games development. The limited resources and complexity of the software and hardware needed to ship modern game titles demanded a different approach.Data-oriented design is inspired by high-performance computing techniques, database design, and functional programming values. It provides a practical methodology that reduces complexity while improving performance of both your development team and your product. Understand the goal, understand the data, understand the hardware, develop the solution.This book presents foundations and principles helping to build a deeper understanding of data-oriented design. It provides instruction on the thought processes involved when considering data as the primary detail of any project.},
	author = {Fabian, Richard},
	urldate = {2024-02-22},
	date = {2018-09-29},
	file = {Data-Oriented Design:C\:\\Users\\OS\\Zotero\\storage\\ZEBJ2XN8\\node2.html:text/html},
}

@article{conwayHowCommitteesInvent1968,
	title = {How do committees invent},
	pages = {28--31},
	number = {14},
	journaltitle = {Datamation},
	shortjournal = {Datamation},
	author = {Conway, Melvin E},
	date = {1968},
	langid = {english},
	file = {Conway - 1968 - HOW DO COMMITTEES INVENT.pdf:C\:\\Users\\OS\\Zotero\\storage\\TLL3MAYW\\Conway - 1968 - HOW DO COMMITTEES INVENT.pdf:application/pdf},
}

@unpublished{levittIntroductionStructuredAnalysis2006,
	title = {Introduction to Structured Analysis and Design},
	url = {https://web.archive.org/web/20060907132222/http://faculty.inverhills.edu/dlevitt/CS%202000%20%28FP%29/Introduction%20to%20Structured%20Analysis%20and%20Design.pdf},
	author = {Levitt, Dave},
	urldate = {2024-02-22},
	date = {2006-09-07},
	file = {PDF Snapshot:C\:\\Users\\OS\\Zotero\\storage\\RCUHPL4L\\2006 - Wayback Machine.pdf:application/pdf},
}

@article{rossStructuredAnalysisSA1977,
	title = {Structured Analysis ({SA}): A Language for Communicating Ideas},
	volume = {{SE}-3},
	issn = {1939-3520},
	url = {https://ieeexplore.ieee.org/document/1702399},
	doi = {10.1109/TSE.1977.229900},
	shorttitle = {Structured Analysis ({SA})},
	abstract = {Structured analysis ({SA}) combines blueprint-like graphic language with the nouns and verbs of any other language to provide a hierarchic, top-down, gradual exposition of detail in the form of an {SA} model. The things and happenings of a subject are expressed in a data decomposition and an activity decomposition, both of which employ the same graphic building block, the {SA} box, to represent a part of a whole. {SA} arrows, representing input, output, control, and mechanism, express the relation of each part to the whole. The paper describes the rationalization behind some 40 features of the {SA} language, and shows how they enable rigorous communication which results frorn disciplined, recursive application of the {SA} maxim: "Everything worth saying about anything worth saying something about must be expressed in six or fewer pieces."},
	pages = {16--34},
	number = {1},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Ross, D.T.},
	urldate = {2024-02-22},
	date = {1977-01},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
	keywords = {Communication system control, Data processing, Databases, Graphic language, Graphics, hierarchic, Mathematical model, Natural languages, requirements analysis, requirements definition, Software design, Solid modeling, Steam engines, structured analysis ({SA}), structured programming, system analysis, System analysis and design, system design, top-down},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\OS\\Zotero\\storage\\KD3LQ5B4\\1702399.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\OS\\Zotero\\storage\\TY8BMLBL\\Ross - 1977 - Structured Analysis (SA) A Language for Communica.pdf:application/pdf},
}

@online{fleuryTaxonomyComputationShapes2023,
	title = {A Taxonomy Of Computation Shapes},
	url = {https://www.rfleury.com/p/a-taxonomy-of-computation-shapes},
	abstract = {A mental model for various forms of computation.},
	author = {Fleury, Ryan},
	urldate = {2024-02-22},
	date = {2023-02-17},
	langid = {english},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\QFWUN7GK\\a-taxonomy-of-computation-shapes.html:text/html},
}

@online{PortugueseMusicianBreaks2017,
	title = {Portuguese musician breaks record for astonishingly fast piano key hitting},
	url = {https://www.guinnessworldrecords.com/news/2017/6/portuguese-musician-breaks-record-for-astonishingly-fast-piano-key-hitting-475329},
	abstract = {Portuguese-American musician Antonio Domingos has proved he has the fastest fingers in the business, after smashing the record for the most piano key hits in one minute.},
	titleaddon = {Guinness World Records},
	urldate = {2024-02-08},
	date = {2017-06-07},
	langid = {english},
	file = {Snapshot:C\:\\Users\\OS\\Zotero\\storage\\KS8TIWRL\\portuguese-musician-breaks-record-for-astonishingly-fast-piano-key-hitting-475329.html:text/html},
}

@online{AnalogWriteArduinoReference,
	title = {{analogWrite}() - Arduino Reference},
	url = {https://www.arduino.cc/reference/en/language/functions/analog-io/analogwrite/},
	urldate = {2024-02-08},
	file = {analogWrite() - Arduino Reference:C\:\\Users\\OS\\Zotero\\storage\\WJ685Z9E\\analogwrite.html:text/html},
}

@online{ShiftRegisterPWMLibraryArduinoReference,
	title = {{ShiftRegister}-{PWM}-Library - Arduino Reference},
	url = {https://www.arduino.cc/reference/en/libraries/shiftregister-pwm-library/},
	urldate = {2024-01-25},
	file = {ShiftRegister-PWM-Library - Arduino Reference:C\:\\Users\\OS\\Zotero\\storage\\RHKUU57C\\shiftregister-pwm-library.html:text/html},
}

@software{bsch2734Bsch2734SpiShiftRegisterChain2022,
	title = {bsch2734/{SpiShiftRegisterChain}},
	rights = {Unlicense},
	url = {https://github.com/bsch2734/SpiShiftRegisterChain},
	abstract = {A simple Arduino library for controlling any length of chained 595 style shift registers over the built in {SPI} bus},
	author = {bsch2734},
	urldate = {2024-01-25},
	date = {2022-04-26},
	note = {original-date: 2022-04-26T02:25:04Z},
	keywords = {arduino, arduino-library, library, shift-register},
}

@article{smpteST12120142014,
	title = {{ST} 12-1:2014 - {SMPTE} Standard - Time and Control Code},
	url = {https://ieeexplore.ieee.org/document/7291029},
	doi = {10.5594/SMPTE.ST12-1.2014},
	shorttitle = {{ST} 12-1},
	abstract = {This Standard specifies a time and control code for use in television and accompanying audio systems operating at nominal rates1 of 60, 59.94, 50, 48, 47.95, 30, 29.97, 25, 24, and 23.98 frames per second. This standard defines a time address, binary groups, and flag bit structure. The standard also defines a binary group flag assignment, a linear time code transport, and a vertical interval time code transport. — This standard defines primary data transport structures for Linear Time Code ({LTC}) and Vertical Interval Time Code ({VITC}). This standard defines the {LTC} modulation and timing for all video formats. This standard also defines the {VITC} modulation and location for 525/59.94 and 625/50 analog composite and component systems only. — Note: The digital representation of analog {VITC} (D-{VITC}) is specified in {SMPTE} {ST} 266 and is defined for 525/59.94 and 625/50 digital component systems only. High Definition formats, such as those documented in {SMPTE} {ST} 2048-2, {SMPTE} {ST} 274, and {SMPTE} {ST} 296, use Ancillary Time Code ({ATC}) as specified in {SMPTE} {ST} 12-2 (formerly {SMPTE} {RP} 188) for transport of time code in the digital video data stream. For future implementations of time code for digital Standard Definition formats, the use of {ATC} rather than D-{VITC} is encouraged. — {NOTE}: This 2014 document is a revision of {ST} 12-1:2008 incorporating changes published as Amendment {ST} 12-1:2008 {AM}1:2013. No further changes have been made.},
	pages = {1--41},
	journaltitle = {{ST} 12-1:2014},
	author = {{SMPTE}},
	urldate = {2024-01-11},
	date = {2014-02},
	note = {Conference Name: {ST} 12-1:2014},
	file = {2014 - ST 12-12014 - SMPTE Standard - Time and Control C.pdf:C\:\\Users\\OS\\Zotero\\storage\\UV6F5XNP\\2014 - ST 12-12014 - SMPTE Standard - Time and Control C.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\OS\\Zotero\\storage\\YVSXK38A\\7291029.html:text/html},
}
